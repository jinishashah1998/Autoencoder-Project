{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Conv2D, Conv3D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom google.colab import drive\n",
    "import glob\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "path = \"/content/gdrive/My Drive/Colourize Autoencoder/Flower Training Set\"\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_data = datagen.flow_from_directory(path, target_size=(256, 256),batch_size=99,class_mode='input')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "ab = []\n",
    "x = 0\n",
    "for image in train_data[0][0]:\n",
    "    try:\n",
    "        plt.imshow(image)\n",
    "        x+=1\n",
    "        lab = rgb2lab(image)\n",
    "        l.append(lab[:,:,0])\n",
    "        ab.append(lab[:,:,1:]/128)\n",
    "    except:\n",
    "        print(\"Error in converting rgb image to lab\")\n",
    "\n",
    "print(\"X: \" + str(x))\n",
    "print(\"SHAPES\")\n",
    "\n",
    "#converting lists l and ab to np.arrays\n",
    "l = np.array(l)\n",
    "ab = np.array(ab)\n",
    "\n",
    "print(\"L  Shape: \" + str(l.shape))\n",
    "print(\"AB Shape: \" + str(ab.shape))\n",
    "\n",
    "#reshaping numpy array np_l\n",
    "l = l.reshape(l.shape + (1,))\n",
    "print(\"*AFTER FIXING SHAPE*\")\n",
    "print(\"L  Shape: \" + str(l.shape) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "en_input = Input(shape=(256, 256, 1,))\n",
    "en_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(en_input)\n",
    "en_output = Conv2D(128, (3,3), activation='relu', padding='same')(en_output)\n",
    "en_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(en_output)\n",
    "en_output = Conv2D(256, (3,3), activation='relu', padding='same')(en_output)\n",
    "en_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(en_output)\n",
    "en_output = Conv2D(512, (3,3), activation='relu', padding='same')(en_output)\n",
    "en_output = Conv2D(512, (3,3), activation='relu', padding='same')(en_output)\n",
    "en_output = Conv2D(256, (3,3), activation='relu', padding='same')(en_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "dec_output = Conv2D(128, (3,3), activation='relu', padding='same')(en_output)\n",
    "dec_output = UpSampling2D((2, 2))(dec_output)\n",
    "dec_output = Conv2D(64, (3,3), activation='relu', padding='same')(dec_output)\n",
    "dec_output = UpSampling2D((2, 2))(dec_output)\n",
    "dec_output = Conv2D(32, (3,3), activation='relu', padding='same')(dec_output)\n",
    "dec_output = Conv2D(16, (3,3), activation='relu', padding='same')(dec_output)\n",
    "dec_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(dec_output)\n",
    "dec_output = UpSampling2D((2, 2))(dec_output)\n",
    "model = Model(inputs=en_input, outputs=dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the data using MSE\n",
    "start = time.time()\n",
    "model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "model.fit(l,ab,validation_split=0.15, epochs=100) #1000\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post processing (do not have test data so just going to use train data for now)\n",
    "test_path = '/content/gdrive/My Drive/Colourize Autoencoder/Flower Testing Dataset/Test (Colour)/'\n",
    "test_path = '/content/gdrive/My Drive/Colourize Autoencoder/Flower Testing Dataset/Test (B-W)/'\n",
    "\n",
    "test_data = os.listdir(test_path)\n",
    "color_me = []\n",
    "for img_name in test_data:\n",
    "    print(img_name)\n",
    "    image = img_to_array(load_img(test_path + img_name))\n",
    "    image = resize(image ,(256,256))\n",
    "    color_me.append(image)\n",
    "\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "#print(color_me.shape)\n",
    "\n",
    "output = model.predict(color_me)\n",
    "print(output.shape)\n",
    "output *= 128\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, format(\"/content/gdrive/My Drive/TESTSAVE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstructing the Lab image - Output colorizations\n",
    "for i in range(len(output)):\n",
    "    result = np.zeros((256, 256, 3))\n",
    "    result[:,:,0] = color_me[i][:,:,0]\n",
    "    result[:,:,1:] = output[i]\n",
    "    #imsave(\"result\"+str(i)+\".png\", lab2rgb(result))\n",
    "    plt.imshow(lab2rgb(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "result[:,:,0] = color_me[i][:,:,0]\n",
    "result[:,:,1:] = output[i]\n",
    "#imsave(\"result\"+str(i)+\".png\", lab2rgb(result))\n",
    "plt.imshow(lab2rgb(result))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# result = np.zeros((256, 256, 3))\n",
    "# result[:,:,1:] = output[i]\n",
    "# plt.imshow(result)\n",
    "# result[:,:,0] = color_me[i][:,:,0]\n",
    "#imsave(\"result\"+str(i)+\".png\", lab2rgb(result))\n",
    "#plt.imshow(lab2rgb(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
